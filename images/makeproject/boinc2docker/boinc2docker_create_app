#!/usr/bin/env python

import argparse
import pwd
import os
from functools import partial
import subprocess
from zipfile import ZipFile
from inspect import currentframe
from textwrap import dedent
from itertools import groupby
from shutil import copy
import stat
from os.path import join, exists, basename, dirname, abspath
import random
import tempfile
import json

sh = lambda cmd: subprocess.check_output(['sh','-c',cmd])

# constructs a function that can format a given string s using both global variables
#and local variables from a specific frame f
fmt = partial(lambda s,f: s.format(**dict(globals(),**f.f_locals)),f=currentframe())

def create_directories(dir):
    if not exists(dir):
    	os.makedirs(dir)

#create list of string for argument parsing function
def list_of_strings(arg):
    return arg.split(',')

def download(f, appfolder):
    tgt = join(appfolder, basename(f))
    sh('wget --progress=bar:force --content-disposition --no-check-certificate %s -O %s' % (f, tgt))
    return tgt


def get_wrapper(platform, appfolder, wrapper):
    """
    Download and unzip wrapper executables from http://boinc.berkeley.edu/dl
    """
    wrapper_root = "wrapper_" + wrapper[platform] + "_" + platform
    wrapper_file = join(appfolder, wrapper_root +
                        ('.exe' if 'windows' in platform else ''))
    if not exists(wrapper_file):
        with ZipFile(download('http://boinc.berkeley.edu/dl/' + wrapper_root + '.zip', appfolder)) as zf:
            with open(wrapper_file, 'wb') as f:
                zi = {basename(z.filename): z for z in zf.filelist}[
                    basename(wrapper_file)]
                f.write(zf.read(zi))
                os.fchmod(f.fileno(), 0o775)

    return wrapper_file


def create_job_description_file(app_name, appfolder):

	fmt = partial(lambda s,f: s.format(**dict(globals(),**f.f_locals)),f=currentframe())

	job_content = fmt(dedent("""
					<job_desc>
						<task>
							<application>{app_name}</application>
						</task>
					</job_desc>

					"""))

	job_path = appfolder + "/" + app_name + ".xml"
	job_file = open(job_path, "w")
	job_file.write(job_content)
	job_file.close()

	return 0


def create_version_desc(wrapper_file, app_name, appfolder):

	fmt = partial(lambda s,f: s.format(**dict(globals(),**f.f_locals)),f=currentframe())

	wrapper = basename(wrapper_file)

	version_content = fmt(dedent("""
					<version>
						<file>
							<physical_name>{wrapper}</physical_name>
							<main_program/>
						</file>
						<file>
							<physical_name>{app_name}</physical_name>
					  		<logical_name>{app_name}</logical_name>
						</file>

						<file>
							<physical_name>{app_name}.xml</physical_name>
							<logical_name>job.xml</logical_name>
						</file>
					</version>

					"""))


	version_path = appfolder + "/" + "version.xml"
	version_file = open(version_path, "w")
	version_file.write(version_content)
	version_file.close()

	return 0


def create_template_in(app_name, uid, gid):

	fmt = partial(lambda s,f: s.format(**dict(globals(),**f.f_locals)),f=currentframe())

	template_name = "/home/boincadm/project/templates/" + app_name + "_in"

	template_in_content =fmt(dedent("""<?xml version=\"1.0\"?>
					<input_template>
   				 		<file_info>
							<number>0</number>
   				 		</file_info>
   				 		<workunit>
       							 <file_ref>
           					 		<file_number>0</file_number>
           					 		<open_name>shared/boinc_app</open_name>
           					 		<copy_file/>
       					 		</file_ref>
    						</workunit>
					</input_template>"""))


	template_in = open(template_name, "w")
	template_in.write(template_in_content)
	template_in.close()

	os.chown(template_name, uid, gid)

	return 0

def create_template_out(app_name, uid, gid):

	fmt = partial(lambda s,f: s.format(**dict(globals(),**f.f_locals)),f=currentframe())

	template_name = "/home/boincadm/project/templates/" + app_name + "_out"

	template_out_content =fmt(dedent("""<?xml version="1.0"?>

						<output_template>

								<file_info>
									<name><OUTFILE_0/>.tgz</name>
									<generated_locally/>
									<upload_when_present/>
									<max_nbytes>134217728</max_nbytes>
									<url><UPLOAD_URL/></url>
								</file_info>

								<result>
									<file_ref>
											<file_name><OUTFILE_0/>.tgz</file_name>
											<open_name>shared/results.tgz</open_name>
											<copy_file>1</copy_file>
											<optional>1</optional>
									</file_ref>
								</result>

						</output_template>
						"""))


	template_out = open(template_name, "w")
	template_out.write(template_out_content)
	template_out.close()

	os.chown(template_name, uid, gid)

	return 0

def create_sign_keys(uid, gid):

	with open("config.xml", "r+") as config:
		contents = config.readlines()
		for line in contents:
			if "key_dir" in line:
				key_dir = (line.split(">"))[1].split("<")[0]

	generate_code_sign_key = "/home/boincadm/project/bin/crypt_prog -genkey 1024 " + key_dir + "/code_sign_private " + key_dir + "/code_sign_public"

	generate_upload_key = "/home/boincadm/project/bin/crypt_prog -genkey 1024 " + key_dir + "/upload_private " + key_dir + "/upload_public"

	if not os.path.isdir(key_dir):
		create_directories(key_dir)

	if not os.path.isfile(key_dir + "/upload_private"):
			subprocess.call(generate_upload_key, shell=True)



	if not os.path.isfile(key_dir + "/code_sign_private"):
			subprocess.call(generate_code_sign_key, shell=True)

	keys = ["/code_sign_private", "/code_sign_public", "/upload_private", "/upload_public"]
	for i in keys:
		os.chown(key_dir + i, uid, gid)

	return 0

#get image id
def get_image_id(image):
    return sh('docker inspect --format "{{ .Id }}" '+image).strip().split(':')[1]

# tmp dir only created on-demand to reduce disk access
_tmpdir=[None]
def tmpdir():
    if _tmpdir[0] is None:
          _tmpdir[0] = tempfile.mkdtemp()
    return _tmpdir[0]

def get_manifest(image_path):
    return json.load(tarfile.open(image_path).extractfile('manifest.json'))

#save image and make
def create_image (app_name, image, input_files):

        path="/home/boincadm/project/docker_image"
        os.mkdir(path)

        path = path + "/" + app_name
        os.mkdir(path)
        
        try:
              image_id = get_image_id(image)
        except subprocess.CalledProcessError as e:
              if 'No such image' in e.output:
                 get_image = "docker pull " + image
                 subprocess.call(get_image, shell=True)
                 image_id = get_image_id(image)
              else:
                 raise

        image_filename_tar = "image_" + image_id + ".tar"
        image_path = path + "/" + image_filename_tar

        if exists(image_path):
             #get description of layers and image
             manifest = get_manifest(image_path)
        else:
             #save docker image, than extracts all contents from tar archive
             #that is being piped in through stdin and then stores them in
             #the current directory specified by
             save_docker_image = "docker save " + image + "| tar xf - -C" + tmpdir()
             subprocess.call(save_docker_image, shell=True)
             manifest = json.load(open(join(tmpdir(), 'manifest.json')))


        for layer in manifest[0]['Layers']:
             layer_id = layer.split("/")[0]
             layer_filename_tar = "layer_" + layer_id + ".tar"
             layer_path = path + "/" + layer_filename_tar

             #create tar file for layers of the image in verbose mode
             print ("Creating tar layer archive %s"%layer_id[:12])
             layer_tar = "tar cvf " + layer_path + " -C " + tmpdir() + " " + layer_id
             sh(layer_tar)
             print ("Creating gzip archive for layer %s"%layer_id[:12])
             layer_zip = "gzip -nfS .manual.gz " + layer_path
             sh(layer_zip)
             input_files.append(layer_path + ".manual.gz")


        #create tar file for image in verbose mode, it consists of image_id, manifest.json and repository
        print ("Creating tar image archive %s"%image_id[:12])
        image_tar = "tar cvf " + image_path + " -C " + tmpdir() + " " + image_id + ".json " + "manifest.json repositories"
        sh(image_tar)
        print ("Creating gzip archive for image %s"%image_id[:12])
        image_zip = "gzip -nfS .manual.gz " + image_path
        sh(image_zip)
        input_files.append(image_path + ".manual.gz")

        stage_directory = "/home/boincadm/project/bin/stage_file " + path
        subprocess.call(stage_directory, shell=True)

        return 0


def make_docker_script(appfolder, app_name, image):

	fmt = partial(lambda s,f: s.format(**dict(globals(),**f.f_locals)),f=currentframe())

	script = fmt(dedent("""#!/bin/sh
              #create temporary directory for image load
              mkdir -p ./image/combined

              #the command unzip all .tar.manual.gz files in directory docker_image and extracts them to the directory image
              for f in ./*.tar.manual.gz; do [ -e $f ] && gunzip -c $f > ./image/$(basename $f .manual.gz); done

              #the command collects all tar files in docker_image and image directories, extracts their contents and combines them into a single directory, named image/combined
              cat $(for f in ./*.tar ./image/*.tar; do [ -e $f ] && echo $f; done) | tar xi -C ./image/combined

              rm  ./image/*.tar
              tar cf - -C ./image/combined . | docker load
              rm -rf ./image

              docker run --rm {image}

	"""))

	docker_script_path = appfolder + "/" + app_name

	docker_script = open(docker_script_path, "w")
	docker_script.write(script)
	docker_script.close()

	os.chmod(docker_script_path, stat.S_IRWXU | stat.S_IRWXG)

	return 0


def add_new_app_to_project(app_name):

	line = "    <app>\n" + "        <name>" + app_name + "</name>\n" + \
    		"        <user_friendly_name>" + app_name + \
    		"</user_friendly_name>\n" + "    </app>\n"

	with open("project.xml", "r+") as project_config:
		contents = project_config.readlines()
		len_contents = len(contents)
		for i in range(len_contents):
			if i == (len_contents - 2):
				contents.insert(i, line)

	with open("project.xml", "r") as file:
		file.close()

	with open("project.xml", "w") as project_config:
		project_config.writelines(contents)


def create_new_plan_class(plan_class_name, plan_class_args):

    #make new plan class to add to the configuration file
    plan_class_line = "     <plan_class>\n" + "        <name>" + plan_class_name + "</name>\n"
    gpu_lib_type = plan_class_line + "        <cuda/>\n" if plan_class_args['gpu_type'] == "nvidia" else plan_class_line + "        <cal/>" if plan_class_args['gpu_type'] == "amd" else "none"
    if (plan_class_args['gpu_type'] != 'none'):
          plan_class_line = plan_class_line + "        <gpu_type>" + plan_class_args['gpu_type'] + "</gpu_type>\n"
          if (plan_class_args['ngpus'] != 0):
             plan_class_line = plan_class_line + "        <ngpus>" + plan_class_args['ngpus'] + "</ngpus>\n"
          if (plan_class_args['min_gpu_ram_mb'] != 0):
             plan_class_line = plan_class_line + "        <min_gpu_ram_mb>" + plan_class_args['min_gpu_ram_mb'] + "</min_gpu_ram_mb>\n"
          if (plan_class_args['gpu_ram_used_mb'] != 0):
             plan_class_line = plan_class_line + "        <gpu_ram_used_mb>" + plan_class_args['gpu_ram_used_mb'] + "</gpu_ram_used_mb>\n"
          if (plan_class_args['gpu_type'] == "amd" and plan_class_args['use_ati_libs']):
             plan_class_line = plan_class_line + "        <need_ati_libs/>\n"
          if (plan_class_args['gpu_type'] == "amd" and plan_class_args['use_amd_libs']):
             plan_class_line = plan_class_line + "        <need_amd_libs/>\n"
          if (plan_class_args['driver_versions'][0] != '0'):
             plan_class_line = plan_class_line + "        <min_driver_version>" + plan_class_args['driver_versions'][0] + "<min_driver_version/>\n"
          if (plan_class_args['driver_versions'][1] != '0'):
             plan_class_line =  plan_class_line + "        <max_driver_version>" + plan_class_args['driver_versions'][1] + "<max_driver_version/>\n"
          if (plan_class_args['gpu_type'] == "nvidia" and plan_class_args['cuda_versions'][0] != '0'):
             plan_class_line =  plan_class_line + "        <min_cuda_version>" + plan_class_args['cuda_versions'][0] + "<min_cuda_version/>\n"
          if (plan_class_args['gpu_type'] == "nvidia" and plan_class_args['cuda_versions'][1] != '0'):
             plan_class_line =  plan_class_line + "        <max_cuda_version>" + plan_class_args['cuda_versions'][1] + "<max_cuda_version/>\n"

    if (plan_class_args['min_ncpus'] > 0 ):
        plan_class_line = plan_class_line + "        <min_ncpus>" + plan_class_args['min_ncpus'] + "<min_ncpus/>\n"
    if (plan_class_args['max_threads'] > 0):
        plan_class_line = plan_class_line + "        <max_threads>" + plan_class_args['max_threads'] + "<max_threads/>\n"
    if (plan_class_args['mem_usage_base_mb'] > 0):
        plan_class_line = plan_class_line + "        <mem_usage_base_mb>" + plan_class_args['mem_usage_base_mb'] + "<mem_usage_base_mb/>\n"
    if (plan_class_args['mem_usage_per_cpu_mb'] > 0):
        plan_class_line = plan_class_line + "        <mem_usage_per_cpu_mb>" + plan_class_args['mem_usage_per_cpu_mb'] + "<mem_usage_per_cpu_mb/>\n"
    plan_class_line = plan_class_line + "     </plan_class>\n"

    with open("plan_class_spec.xml", "r+") as plan_class_config:
                contents = plan_class_config.readlines()
                len_contents = len(contents)
                for i in range(len_contents):
                        if i == (len_contents - 1):
                                contents.insert(i, plan_class_line)

    with open("plan_class_spec.xml", "r") as file:
                file.close()

    with open("plan_class_spec.xml", "w") as project_config:
                project_config.writelines(contents)

    return 0


def add_new_app(app_name, image, plan_class_name):

    uid = pwd.getpwnam('boincadm').pw_uid
    gid = pwd.getpwnam('boincadm').pw_gid

    # stop all daemons for adding new app
    subprocess.call("/home/boincadm/project/bin/stop")

    #path for app directories
    approot = "/home/boincadm/project/"

    app_path = ["apps", app_name, "1.0.0"]

    for path in app_path:
        approot = approot + path + "/"
        create_directories(approot)
        os.chown(approot, uid, gid)

    print(approot)

    #get wrapper, version, docker_script, job.xml to app_directories
    platforms = ["x86_64-pc-linux-gnu", "windows_x86_64", "x86_64-apple-darwin"]
    wrapper = {"x86_64-pc-linux-gnu": "26015", "windows_x86_64": "26015", "x86_64-apple-darwin":"26015"}
    for platform in platforms:

            # create app directories
            appfolder = join(approot, platform + '__' + plan_class_name)
            create_directories(appfolder)
            os.chown(appfolder, uid, gid)

            # get wrapper
            wrapper_file = get_wrapper(platform, appfolder, wrapper)
            os.chown(wrapper_file, uid, gid)

            print("create app version")

            # create version description
            create_version_desc(wrapper_file, app_name, appfolder)
            os.chown(appfolder + "/version.xml", uid, gid)

            print("create docker script")

            # create docker script
            make_docker_script(appfolder, app_name, image)
            os.chown(appfolder + "/" + app_name, uid, gid)

            print("create job file")

             # create job.xml file
            create_job_description_file(app_name, appfolder)
            os.chown(appfolder + "/" + app_name + ".xml", uid, gid)

            if platform != "windows_x86_64":
                if os.path.isfile(wrapper_file + ".zip"):
                    os.remove(wrapper_file + ".zip")
            else:
                if os.path.isfile(appfolder + "/wrapper_26015_windows_x86_64.zip"):
                    os.remove(appfolder + "/wrapper_26015_windows_x86_64.zip")

    print("add the application to the project")

    #add new application to project.xml
    add_new_app_to_project(app_name)

    print("create template_in")

    #create template_in
    create_template_in(app_name, uid, gid)

    print("create template_out")

    #create template_out
    create_template_out(app_name, uid, gid)

    create_sign_keys(uid, gid)

    print("run command bin/xadd for adding new application")

    # run command bin/xadd for adding new application
    subprocess.call("/home/boincadm/project/bin/xadd")

    print("run command bin/update_versions for adding application version")

    subprocess.call("/home/boincadm/project/bin/update_versions")

    # run command bin/update_versions for adding application version

    print("start daemons")

    # start daemons
    subprocess.call("/home/boincadm/project/bin/start")

    os.chown("/home/boincadm/project/download/" + app_name, uid, gid)

    os.chown("/home/boincadm/project/download/" + app_name + ".xml", uid, gid)

    for i in wrapper:
        if i != "windows_x86_64":
            os.chown("/home/boincadm/project/download/wrapper_" + wrapper[i] + "_" + i, uid, gid)
        else:
            os.chown("/home/boincadm/project/download/wrapper_" + wrapper[i] + "_" + i + ".exe", uid, gid)

def create_input_files(input_files):
	for i in input_files:
		stage_input_files = "/home/boincadm/project/bin/stage_file" + i
		subprocess.call(stage_input_files, shell=True)
	return 0

def create_new_job(app_name, image, new, plan_class_name, plan_class_new, plan_class_args, input_files):
	if plan_class_new:
		create_new_plan_class(plan_class_name, plan_class_args)

	if new:
		add_new_app(app_name, image, plan_class_name)

	create_image(app_name, image, input_files)

	create_input_files(input_files)
	random_string = ""
	for i in [0, 1, 2, 3, 4]:
		random_string = random_string + random.choice("abcdefghijklmnopqrstuvwxyz")

	input_files_names = ""
	last_item = input_files[-1]
	for i in input_files:
		if (i != last_item):
			input_files_names = input_files_names + i  + ", "
		else:
			input_files_names = input_files_names + i

	wu_name = app_name + "_" + random_string

	create_work_command = "/home/boincadm/project/bin/create_work --appname " + app_name + " --wu_name " + wu_name + input_files_names

	subprocess.call(create_work_command, shell=True)
		
	return 0

if __name__=='__main__':
    parser = argparse.ArgumentParser(prog='create_new_job')
    parser.add_argument('--appname', default='boinc_docker', help='appname (default: boinc2docker)')
    parser.add_argument('--new_app', action='store_true', help='add new application to the BOINC server')
    parser.add_argument('--image', default='hello-world', help='docker image to run (default: hello-world)')
    parser.add_argument('--plan_class_new', action='store_true', help='add new plan class to the BOINC server, if mentioned with flag new_app, than the application will be created with new specified plan class')
    parser.add_argument('--plan_class_name', default='standart', help='name of the plan class')
    parser.add_argument('--gpu_type', default='none', choices=['nvidia', 'amd'], help='type of the gpu')
    parser.add_argument('--min_gpu_ram_mb', default=0, help='minimum amount of GPU RAM in MB')
    parser.add_argument('--gpu_ram_used_mb', default=0, help='requirement of this much available GPU RAM in MB')
    parser.add_argument('--ngpus', default=0, help='amount of gpus to use')
    parser.add_argument('--driver_versions', type=list_of_strings, help='range of available gpu driver versions' )
    parser.add_argument('--cuda_versions', type=list_of_strings, help='range of available cuda versions, the flag is used only for nvidia gpus' )
    parser.add_argument('--use_ati_libs', action='store_true', help='require libraries named ati, the flag is used for ATI/AMD gpus')
    parser.add_argument('--use_amd_libs', action='store_true', help='require libraries named amd, the flag is used for ATI/AMD gpus')
    parser.add_argument('--min_ncpus', default=0, help='minimal amount of processors to use')
    parser.add_argument('--max_threads', default=0, help='maximal amount of threads to use')
    parser.add_argument('--mem_usage_base_mb', default=0, help='memmory usage')
    parser.add_argument('--mem_usage_per_cpu_mb', default=0, help='if specified, estimated memory usage is X + NY, where X is mem_usage_base_mb, N is amount of processors, Y is mem_usage_per_cpu_mb')
    parser.add_argument('--input_files', type=list_of_strings, help='list of input_files for the job')
    args = parser.parse_args()

    plan_class_args = {'gpu_type': args.gpu_type, 'min_gpu_ram_mb':args.min_gpu_ram_mb, 'gpu_ram_used_mb':args.gpu_ram_used_mb, 'ngpus':args.ngpus, 'driver_versions':args.driver_versions, 'cuda_versions':args.cuda_versions, 'use_ati_libs':args.use_ati_libs, 'use_amd_libs': args.use_amd_libs, 'min_ncpus':args.min_ncpus, 'max_threads':args.max_threads, 'mem_usage_base_mb':args.mem_usage_base_mb, 'mem_usage_per_cpu_mb':args.mem_usage_per_cpu_mb}
    create_new_job(app_name=args.appname, input_files=args.input_files, image=args.image, new=args.new, plan_class_name=args.plan_class_name, plan_class_new=args.plan_class_new, plan_class_args=plan_class_args, input_files=args.input_files)
